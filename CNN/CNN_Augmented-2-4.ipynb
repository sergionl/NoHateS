{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTqhrPaSeE-z"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL1iFjECh3_6"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -qq\n",
        "# !pip install sentencepiece -qq\n",
        "# !pip install tokenizer -qq\n",
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La-lPuGjCxbb"
      },
      "source": [
        "## Set Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnuQNrQ5Cxi_",
        "outputId": "7362def3-6fad-4e21-c042-0aaec25c5496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-pzooQXh5S7"
      },
      "source": [
        "##Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VDNtrBAVEc_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def to_df(x, y):\n",
        "    d = {\"text\": x, \"label\": y}\n",
        "    return pd.DataFrame(d)\n",
        "\n",
        "def split_3(df, test_size=0.2, valid_size=0.2):\n",
        "    _df = df.copy().sample(frac=1).reset_index()\n",
        "    _df = _df[[\"text\", \"label\"]]\n",
        "\n",
        "    x = df[\"text\"].copy()\n",
        "    y = df[\"label\"].copy()\n",
        "    #split train-test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y, random_state=SEED)\n",
        "    # split train-valid\n",
        "    x, y = x_train, y_train\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=valid_size, stratify=y, random_state=SEED)\n",
        "    return to_df(x_train, y_train), to_df(x_valid, y_valid), to_df(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOeulLaVVEc_",
        "outputId": "15aa05ad-6833-439b-c32a-3f32744fa51f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from itertools import chain\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "from nlpaug.util import Action\n",
        "\n",
        "\n",
        "alpha_common_error = 0.10\n",
        "alpha_common_error_char = 0.05\n",
        "aug1_OCR = nac.OcrAug(aug_word_p=alpha_common_error)\n",
        "aug2_Rins = nac.RandomCharAug(action=\"insert\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug3_Rsub = nac.RandomCharAug(action=\"substitute\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug4_Rswa = nac.RandomCharAug(action=\"swap\", aug_word_p=alpha_common_error,aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char) #\n",
        "aug5_Rdel = nac.RandomCharAug(action=\"delete\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug6_Kb = nac.KeyboardAug(aug_word_p=alpha_common_error)\n",
        "aug7_Split = naw.SplitAug(aug_p=alpha_common_error)\n",
        "\n",
        "\n",
        "def text2augment(text, m):\n",
        "    output = [text, ]\n",
        "\n",
        "    temp = random.sample(range(0, 7), m - 1)\n",
        "\n",
        "    if 0 in temp:\n",
        "        output.append( *aug1_OCR.augment(text))\n",
        "    if 1 in temp:\n",
        "        output.append( *aug2_Rins.augment(text))\n",
        "    if 2 in temp:\n",
        "        output.append( *aug3_Rsub.augment(text))\n",
        "    if 3 in temp:\n",
        "        output.append( *aug4_Rswa.augment(text))\n",
        "    if 4 in temp:\n",
        "        output.append( *aug5_Rdel.augment(text))\n",
        "    if 5 in temp:\n",
        "        output.append( *aug6_Kb.augment(text))\n",
        "    if 6 in temp:\n",
        "        output.append( *aug7_Split.augment(text))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def aug_replicate(y_labels):\n",
        "    return list(chain(* [[y]*(2 if y == 0 else 4) for y in y_labels] ))\n",
        "\n",
        "def aug_text(x_text, y_labels):\n",
        "    x_text = [ text2augment(x, 2 if y == 0 else 4) for x, y in zip(x_text, y_labels)]\n",
        "    return pd.Series(list(chain(*x_text)), index=None)\n",
        "\n",
        "def split_3_aug(df, test_size=0.2, valid_size=0.2):\n",
        "    _df = df.copy().sample(frac=1).reset_index()\n",
        "    _df = _df[[\"text\", \"label\"]]\n",
        "\n",
        "    x = _df[\"text\"].copy()\n",
        "    y = _df[\"label\"].copy()\n",
        "    #split train-test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y, random_state=SEED)\n",
        "    # augment\n",
        "    # x_test = aug_text(x_test, y_test)\n",
        "    # y_test = aug_replicate(y_test)\n",
        "    # split train-valid\n",
        "    x, y = x_train, y_train\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=valid_size, stratify=y, random_state=SEED)\n",
        "    # augment\n",
        "    x_train = aug_text(x_train, y_train)\n",
        "    y_train = aug_replicate(y_train)\n",
        "    x_valid = aug_text(x_valid, y_valid)\n",
        "    y_valid = aug_replicate(y_valid)\n",
        "\n",
        "    print(x_valid.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_valid))\n",
        "\n",
        "    print(x_train.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_train))\n",
        "\n",
        "    return to_df(x_train, y_train), to_df(x_valid, y_valid), to_df(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTMXPNE2W6NJ",
        "outputId": "034f5eb6-1290-451f-a392-ac7a05f68449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6724,)\n",
            "DONE\n",
            "6724\n",
            "(26886,)\n",
            "DONE\n",
            "26886\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tname_data = \"./hsd_merge_cleaned_lowered\"\n",
        "data = pd.read_csv(f\"{tname_data}.csv\")\n",
        "\n",
        "train, valid, test = split_3_aug(data)\n",
        "\n",
        "X_train = train['text']\n",
        "y_train = train['label']\n",
        "\n",
        "X_valid = valid['text']\n",
        "y_valid = valid['label']\n",
        "\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHV2PrVfiBLg"
      },
      "source": [
        "# Extract feature by using BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MreD1ev6AgXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "train_sentences = list(train['text'].values)\n",
        "train_labels = list(train['label'].values)\n",
        "\n",
        "valid_sentences = list(valid['text'].values)\n",
        "valid_labels = list(valid['label'].values)\n",
        "\n",
        "test_sentences = list(test['text'].values)\n",
        "test_labels = list(test['label'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNVMN4YPiNjp"
      },
      "source": [
        "Load tokenizer of BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8SPqPcA8BS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PNp5aRVA-Hb",
        "outputId": "bbeae07b-1bd6-439e-aca1-ebdbfe6dd348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(23, 827),\n",
              " (21, 773),\n",
              " (22, 770),\n",
              " (24, 756),\n",
              " (17, 744),\n",
              " (25, 737),\n",
              " (15, 728),\n",
              " (20, 720),\n",
              " (26, 705),\n",
              " (19, 704),\n",
              " (12, 703),\n",
              " (18, 700),\n",
              " (11, 694),\n",
              " (16, 689),\n",
              " (14, 670),\n",
              " (13, 666),\n",
              " (27, 639),\n",
              " (29, 619),\n",
              " (28, 618),\n",
              " (10, 594),\n",
              " (31, 585),\n",
              " (9, 576),\n",
              " (30, 548),\n",
              " (33, 545),\n",
              " (32, 510),\n",
              " (34, 483),\n",
              " (36, 386),\n",
              " (37, 378),\n",
              " (8, 378),\n",
              " (35, 372),\n",
              " (7, 356),\n",
              " (39, 323),\n",
              " (38, 307),\n",
              " (41, 286),\n",
              " (42, 269),\n",
              " (40, 264),\n",
              " (43, 242),\n",
              " (6, 239),\n",
              " (49, 238),\n",
              " (46, 234),\n",
              " (53, 234),\n",
              " (44, 233),\n",
              " (47, 231),\n",
              " (51, 231),\n",
              " (50, 230),\n",
              " (45, 224),\n",
              " (48, 217),\n",
              " (56, 214),\n",
              " (54, 211),\n",
              " (52, 208),\n",
              " (57, 208),\n",
              " (55, 198),\n",
              " (58, 193),\n",
              " (60, 183),\n",
              " (59, 181),\n",
              " (5, 177),\n",
              " (61, 175),\n",
              " (62, 159),\n",
              " (66, 143),\n",
              " (64, 142),\n",
              " (65, 140),\n",
              " (63, 132),\n",
              " (67, 118),\n",
              " (68, 114),\n",
              " (69, 108),\n",
              " (4, 97),\n",
              " (72, 77),\n",
              " (70, 72),\n",
              " (71, 54),\n",
              " (73, 54),\n",
              " (74, 46),\n",
              " (3, 45),\n",
              " (76, 44),\n",
              " (75, 43),\n",
              " (77, 27),\n",
              " (79, 19),\n",
              " (80, 19),\n",
              " (78, 19),\n",
              " (81, 17),\n",
              " (82, 12),\n",
              " (2, 12),\n",
              " (83, 8),\n",
              " (89, 6),\n",
              " (87, 6),\n",
              " (85, 5),\n",
              " (1, 4),\n",
              " (86, 4),\n",
              " (84, 3),\n",
              " (88, 3),\n",
              " (93, 2),\n",
              " (92, 2),\n",
              " (96, 1),\n",
              " (97, 1),\n",
              " (95, 1),\n",
              " (100, 1),\n",
              " (102, 1),\n",
              " (105, 1),\n",
              " (112, 1)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# #choose max_length for phobert model based on the input length\n",
        "\n",
        "# max_length = 0\n",
        "# list_len=[]\n",
        "# for sentence in train_sentences:\n",
        "#     length = len(tokenizer.tokenize(sentence))\n",
        "#     list_len.append(length)\n",
        "\n",
        "# from collections import Counter\n",
        "# Counter(list_len).most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5lBYCTD9bU"
      },
      "outputs": [],
      "source": [
        "# Encode train label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "encoded_labels = le.transform(train_labels)\n",
        "encoded_test_labels = le.transform(valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9XdWNkpFBgH",
        "outputId": "d7cd1781-9749-4125-d5a8-f3a660a8f605"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  ojalá cachen los comunistas de cartón de chile como son los comunistas de verdad para q dejen de andar haciendo el loco\n",
            "Token IDs: tensor([    4, 29596, 14676,  1014,  1065, 18411,  1008, 23638,  1008,  9899,\n",
            "        30931,  1184,  1404,  1065, 18411,  1008,  1836,  1110,  1033, 13812,\n",
            "         1008, 12329,  2391,  1040,  4478,     5,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Tokens IDs tensor\n",
        "\n",
        "def encoder_generator(sentences,labels):\n",
        "\n",
        "    sent_index = []\n",
        "    input_ids = []\n",
        "    attention_masks =[]\n",
        "\n",
        "    for index,sent in enumerate(sentences):\n",
        "\n",
        "        sent_index.append(index)\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=50,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             truncation = True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids,dim=0).cuda()\n",
        "    attention_masks = torch.cat(attention_masks,dim=0).cuda()\n",
        "    labels = torch.tensor(labels).cuda()\n",
        "    sent_index = torch.tensor(sent_index).cuda()\n",
        "\n",
        "    return sent_index,input_ids,attention_masks,labels\n",
        "\n",
        "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,encoded_labels)\n",
        "valid_sent_index,valid_input_ids,valid_attention_masks,valid_encoded_label_tensors = encoder_generator(valid_sentences,encoded_test_labels)\n",
        "print('Original: ', train_sentences[0])\n",
        "print('Token IDs:', train_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYbqZ7NMMWw",
        "outputId": "639ca3da-af50-4d20-ebdd-263bddc13249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data samples is 26886\n",
            "valid data samples is 6724\n"
          ]
        }
      ],
      "source": [
        "# Connvert train, dev input by using TensorDataset\n",
        "\n",
        "from torch.utils.data import TensorDataset,random_split\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
        "valid_dataset = TensorDataset(valid_input_ids,valid_attention_masks,valid_encoded_label_tensors)\n",
        "\n",
        "print('train data samples is {}'.format(len(train_dataset)))\n",
        "print(\"valid data samples is {}\".format(len(valid_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em9Q1v0BMZZX"
      },
      "outputs": [],
      "source": [
        "# Set cuda by using device\n",
        "\n",
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "bs=128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=bs)\n",
        "valid_data_loader = DataLoader(valid_dataset,\n",
        "                              sampler=RandomSampler(valid_dataset),\n",
        "                              batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEtD7kn4jbTl"
      },
      "source": [
        "Load model BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "92b478ab8c8e4a0daa999aad57e95ac3",
            "2bc8b1500a1c41bd807761a54bf916bb",
            "9ef62896ca1b43c18c1adf8a282ef398",
            "cc4bb9d6a8e948cba93d31d073ac03af",
            "a864f46b0bd545a7bd1e974c107e4ef8",
            "02e5d40f71764e9994ec9223756a8e69",
            "6d1c543f9c8e431582ea5bee80a1a1aa",
            "e94092c637004e37a98cbbc13bc8a8b9",
            "b9a4f2122c874921a99f81f72b49c8c1",
            "71cbdcbf71284cfd96b9ad5259f1c7c0",
            "26b3d8d6fde64d82ad49dc81b193275f"
          ]
        },
        "id": "sQiHRn2zMdIJ",
        "outputId": "c561baf0-dfa7-436b-bfab-ad0a0307ca74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "beto = AutoModel.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "beto = beto.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEv63LPpjkcK"
      },
      "source": [
        "# Build CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q44-J-QWMgKQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNNForNLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, num_filters, filter_sizes):\n",
        "        super(CNNForNLP, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embedding_dim, num_filters, filter_size)\n",
        "            for filter_size in filter_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x, _):\n",
        "        embedded = self.embedding(x)  # x: (batch_size, sequence_length)\n",
        "        embedded = embedded.permute(0, 2, 1)  # embedded: (batch_size, embedding_dim, sequence_length)\n",
        "        feature_maps = []\n",
        "        for conv in self.convs:\n",
        "            feature_map = torch.relu(conv(embedded))  # feature_map: (batch_size, num_filters, H)\n",
        "            pooled = torch.max(feature_map, dim=2)[0]  # pooled: (batch_size, num_filters)\n",
        "            feature_maps.append(pooled)\n",
        "        combined = torch.cat(feature_maps, dim=1)  # combined: (batch_size, len(filter_sizes) * num_filters)\n",
        "        combined = self.dropout(combined)\n",
        "        logits = self.fc(combined)  # logits: (batch_size, num_classes)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTo_bpEeMqgr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Definir los parámetros del modelo\n",
        "vocab_size = 31002#tamaño del vocabulario\n",
        "embedding_dim = 768 #Dimension de los vectores de embedding\n",
        "num_classes = 2 #numero de clases o categorias de clasificacion\n",
        "num_filters = 32  #numero de filtros convolucionales\n",
        "filter_sizes = [3]  #tamaño de los filtros convolucionales\n",
        "\n",
        "\n",
        "CNNmodel = CNNForNLP(vocab_size,embedding_dim,num_classes,num_filters,filter_sizes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8QAddNK0rMj",
        "outputId": "ebd45748-066b-44ed-a887-52798434647f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNNForNLP(\n",
            "  (embedding): Embedding(31002, 768)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imprimir el modelo\n",
        "print(CNNmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITmi7WZDMsl6"
      },
      "outputs": [],
      "source": [
        "# Optimizer and criterion\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "model_parameters = list(CNNmodel.parameters())\n",
        "\n",
        "optimizer = optim.Adam(model_parameters,lr=2e-5,eps=1e-8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyp8HhAxMvQH"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy per batch during train\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrVcBEVoMxov"
      },
      "outputs": [],
      "source": [
        "# Def for training\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_data_loader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        loss = criterion(predictions, b_labels)\n",
        "\n",
        "        acc = categorical_accuracy(predictions, b_labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQGFfnFMz-d"
      },
      "outputs": [],
      "source": [
        "# Class for predict label\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    pred = np.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_4Y1RhlM17e"
      },
      "outputs": [],
      "source": [
        "# Evaluate loss, acc  and f1-macro\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
        "def eval(model):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    total_predictions = []\n",
        "    total_true = []\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in tqdm(valid_data_loader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "            loss = criterion(predictions, b_labels)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            pred,true = predictions_labels(predictions,label_ids)\n",
        "\n",
        "            all_pred_labels.extend(pred)\n",
        "            all_true_labels.extend(true)\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
        "\n",
        "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICyenO-tM35S"
      },
      "outputs": [],
      "source": [
        "# Time for training\n",
        "\n",
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OrAOzamNC0e",
        "outputId": "caf37e15-8576-4cfd-94e0-74ab261577f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNForNLP(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device and gpu\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "CNNmodel.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJBkClEkam2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o45rX8rFVEdB"
      },
      "outputs": [],
      "source": [
        "tempname = \"./cnn_aug_model2-4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfHllZjgM5uw",
        "outputId": "102f286f-dad1-4a1b-f6f3-b9fbfedb9430"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:04<00:00, 45.47it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 557.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.71      0.83      6456\n",
            "           1       0.09      0.69      0.16       268\n",
            "\n",
            "    accuracy                           0.71      6724\n",
            "   macro avg       0.54      0.70      0.49      6724\n",
            "weighted avg       0.95      0.71      0.80      6724\n",
            "\n",
            "accuracy = 0.71\n",
            "model saved\n",
            "Epoch: 01 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.617 | Train acc: 66.56%\n",
            "\t Val. Loss: 0.573 |  Val. acc: 71.33%\n",
            "\t Val. Loss: 0.573 |  Val. F1: 49.44%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 95.36it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 490.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.72      0.83      6334\n",
            "           1       0.14      0.71      0.23       390\n",
            "\n",
            "    accuracy                           0.72      6724\n",
            "   macro avg       0.56      0.72      0.53      6724\n",
            "weighted avg       0.93      0.72      0.80      6724\n",
            "\n",
            "accuracy = 0.72\n",
            "model saved\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.563 | Train acc: 71.60%\n",
            "\t Val. Loss: 0.549 |  Val. acc: 72.19%\n",
            "\t Val. Loss: 0.549 |  Val. F1: 52.92%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.47it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 435.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.73      0.83      6234\n",
            "           1       0.17      0.72      0.28       490\n",
            "\n",
            "    accuracy                           0.73      6724\n",
            "   macro avg       0.57      0.73      0.56      6724\n",
            "weighted avg       0.91      0.73      0.79      6724\n",
            "\n",
            "accuracy = 0.73\n",
            "model saved\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.534 | Train acc: 73.41%\n",
            "\t Val. Loss: 0.529 |  Val. acc: 72.99%\n",
            "\t Val. Loss: 0.529 |  Val. F1: 55.69%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.11it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 554.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.75      0.84      6009\n",
            "           1       0.26      0.74      0.39       715\n",
            "\n",
            "    accuracy                           0.75      6724\n",
            "   macro avg       0.61      0.75      0.61      6724\n",
            "weighted avg       0.89      0.75      0.79      6724\n",
            "\n",
            "accuracy = 0.75\n",
            "model saved\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.511 | Train acc: 75.07%\n",
            "\t Val. Loss: 0.514 |  Val. acc: 74.91%\n",
            "\t Val. Loss: 0.514 |  Val. F1: 61.41%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.30it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 557.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.76      0.85      5913\n",
            "           1       0.30      0.74      0.42       811\n",
            "\n",
            "    accuracy                           0.76      6724\n",
            "   macro avg       0.63      0.75      0.63      6724\n",
            "weighted avg       0.88      0.76      0.79      6724\n",
            "\n",
            "accuracy = 0.76\n",
            "model saved\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.493 | Train acc: 76.17%\n",
            "\t Val. Loss: 0.502 |  Val. acc: 75.62%\n",
            "\t Val. Loss: 0.502 |  Val. F1: 63.45%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 96.32it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 542.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.76      0.85      5905\n",
            "           1       0.30      0.75      0.43       819\n",
            "\n",
            "    accuracy                           0.76      6724\n",
            "   macro avg       0.63      0.76      0.64      6724\n",
            "weighted avg       0.88      0.76      0.80      6724\n",
            "\n",
            "accuracy = 0.76\n",
            "model saved\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.480 | Train acc: 76.95%\n",
            "\t Val. Loss: 0.495 |  Val. acc: 75.89%\n",
            "\t Val. Loss: 0.495 |  Val. F1: 63.92%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.68it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 563.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85      5701\n",
            "           1       0.37      0.73      0.49      1023\n",
            "\n",
            "    accuracy                           0.77      6724\n",
            "   macro avg       0.65      0.75      0.67      6724\n",
            "weighted avg       0.85      0.77      0.79      6724\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.467 | Train acc: 77.67%\n",
            "\t Val. Loss: 0.485 |  Val. acc: 76.67%\n",
            "\t Val. Loss: 0.485 |  Val. F1: 66.77%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 93.39it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 499.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      5610\n",
            "           1       0.39      0.72      0.51      1114\n",
            "\n",
            "    accuracy                           0.77      6724\n",
            "   macro avg       0.66      0.75      0.68      6724\n",
            "weighted avg       0.84      0.77      0.79      6724\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.455 | Train acc: 78.59%\n",
            "\t Val. Loss: 0.482 |  Val. acc: 76.92%\n",
            "\t Val. Loss: 0.482 |  Val. F1: 67.80%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 94.05it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 514.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.78      0.85      5660\n",
            "           1       0.39      0.74      0.51      1064\n",
            "\n",
            "    accuracy                           0.77      6724\n",
            "   macro avg       0.66      0.76      0.68      6724\n",
            "weighted avg       0.85      0.77      0.80      6724\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.443 | Train acc: 79.14%\n",
            "\t Val. Loss: 0.476 |  Val. acc: 77.33%\n",
            "\t Val. Loss: 0.476 |  Val. F1: 68.03%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 95.49it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 499.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.85      5569\n",
            "           1       0.41      0.73      0.53      1155\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.67      0.76      0.69      6724\n",
            "weighted avg       0.84      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.434 | Train acc: 79.55%\n",
            "\t Val. Loss: 0.472 |  Val. acc: 77.62%\n",
            "\t Val. Loss: 0.472 |  Val. F1: 69.05%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 94.68it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 552.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.78      0.85      5620\n",
            "           1       0.40      0.74      0.52      1104\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.67      0.76      0.69      6724\n",
            "weighted avg       0.85      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 11 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.424 | Train acc: 80.37%\n",
            "\t Val. Loss: 0.468 |  Val. acc: 77.57%\n",
            "\t Val. Loss: 0.468 |  Val. F1: 68.64%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.64it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 524.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86      5549\n",
            "           1       0.43      0.74      0.54      1175\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.68      0.76      0.70      6724\n",
            "weighted avg       0.84      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 12 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.414 | Train acc: 81.13%\n",
            "\t Val. Loss: 0.464 |  Val. acc: 78.00%\n",
            "\t Val. Loss: 0.464 |  Val. F1: 69.72%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 92.04it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 524.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      5472\n",
            "           1       0.45      0.73      0.55      1252\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.69      0.76      0.71      6724\n",
            "weighted avg       0.84      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 13 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.405 | Train acc: 81.54%\n",
            "\t Val. Loss: 0.461 |  Val. acc: 78.26%\n",
            "\t Val. Loss: 0.461 |  Val. F1: 70.55%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 93.31it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 587.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86      5500\n",
            "           1       0.44      0.74      0.55      1224\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.69      0.77      0.71      6724\n",
            "weighted avg       0.84      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 14 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.398 | Train acc: 82.14%\n",
            "\t Val. Loss: 0.458 |  Val. acc: 78.41%\n",
            "\t Val. Loss: 0.458 |  Val. F1: 70.58%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 94.58it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 546.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86      5501\n",
            "           1       0.44      0.74      0.56      1223\n",
            "\n",
            "    accuracy                           0.78      6724\n",
            "   macro avg       0.69      0.77      0.71      6724\n",
            "weighted avg       0.84      0.78      0.80      6724\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 15 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.392 | Train acc: 82.62%\n",
            "\t Val. Loss: 0.456 |  Val. acc: 78.48%\n",
            "\t Val. Loss: 0.456 |  Val. F1: 70.67%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 94.19it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 539.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      5510\n",
            "           1       0.45      0.75      0.56      1214\n",
            "\n",
            "    accuracy                           0.79      6724\n",
            "   macro avg       0.69      0.77      0.71      6724\n",
            "weighted avg       0.85      0.79      0.81      6724\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 16 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.384 | Train acc: 83.02%\n",
            "\t Val. Loss: 0.453 |  Val. acc: 78.70%\n",
            "\t Val. Loss: 0.453 |  Val. F1: 70.92%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 96.48it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 540.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      5482\n",
            "           1       0.45      0.74      0.56      1242\n",
            "\n",
            "    accuracy                           0.79      6724\n",
            "   macro avg       0.69      0.77      0.71      6724\n",
            "weighted avg       0.84      0.79      0.81      6724\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 17 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.376 | Train acc: 83.36%\n",
            "\t Val. Loss: 0.451 |  Val. acc: 78.79%\n",
            "\t Val. Loss: 0.451 |  Val. F1: 71.21%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 96.94it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 518.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      5460\n",
            "           1       0.46      0.74      0.57      1264\n",
            "\n",
            "    accuracy                           0.79      6724\n",
            "   macro avg       0.70      0.77      0.72      6724\n",
            "weighted avg       0.84      0.79      0.81      6724\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 18 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.365 | Train acc: 84.29%\n",
            "\t Val. Loss: 0.450 |  Val. acc: 78.94%\n",
            "\t Val. Loss: 0.450 |  Val. F1: 71.55%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 95.79it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 563.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      5475\n",
            "           1       0.46      0.75      0.57      1249\n",
            "\n",
            "    accuracy                           0.79      6724\n",
            "   macro avg       0.70      0.78      0.72      6724\n",
            "weighted avg       0.85      0.79      0.81      6724\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 19 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.360 | Train acc: 84.80%\n",
            "\t Val. Loss: 0.449 |  Val. acc: 79.13%\n",
            "\t Val. Loss: 0.449 |  Val. F1: 71.72%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 211/211 [00:02<00:00, 95.01it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 569.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.80      0.86      5492\n",
            "           1       0.46      0.75      0.57      1232\n",
            "\n",
            "    accuracy                           0.79      6724\n",
            "   macro avg       0.70      0.78      0.72      6724\n",
            "weighted avg       0.85      0.79      0.81      6724\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 20 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.349 | Train acc: 85.44%\n",
            "\t Val. Loss: 0.446 |  Val. acc: 79.09%\n",
            "\t Val. Loss: 0.446 |  Val. F1: 71.56%\n",
            "=============Epoch Ended==============\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "\n",
        "best_macro_f1 = float('0')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train(CNNmodel)\n",
        "    valid_loss,valid_acc,macro_f1 = eval(CNNmodel)\n",
        "    end_time = time.time()\n",
        "\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if macro_f1 > best_macro_f1:\n",
        "        best_macro_f1 = macro_f1\n",
        "    torch.save(CNNmodel, tempname +'_task2a_2.pt')\n",
        "    print(\"model saved\")\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc: {valid_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1: {macro_f1*100:.2f}%')\n",
        "    print('=============Epoch Ended==============')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KyQlcVfnCWHw"
      },
      "outputs": [],
      "source": [
        "# Save BETO and CNN\n",
        "\n",
        "# torch.save(CNNmodel, tempname + 'module2_part1.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCzo5AKq8lka"
      },
      "source": [
        "## EVALUATING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftons15Hw8lB",
        "outputId": "ee6c4231-6620-433b-dbf0-59472aed616a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNForNLP(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load phobert and cnn\n",
        "\n",
        "import torch\n",
        "CNNmodel = torch.load(tempname + '_task2a_2.pt')\n",
        "CNNmodel.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6sFPdMFlPRp"
      },
      "source": [
        "Predict label from true label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U9Co-AvE_Ehq",
        "outputId": "6b259862-cded-4a0a-ba61-369df4487e4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 28/28 [00:00<00:00, 560.01it/s]\n"
          ]
        }
      ],
      "source": [
        "test_sent_index, test_input_ids, test_attention_masks, test_encoded_label_tensors = encoder_generator(test_sentences,test_labels)\n",
        "test_dataset = TensorDataset(test_input_ids,test_attention_masks,test_encoded_label_tensors)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset,\n",
        "                              sampler=RandomSampler(test_dataset),\n",
        "                              batch_size=bs)\n",
        "\n",
        "all_pred_labels = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(test_data_loader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    predictions = CNNmodel(b_input_ids,b_input_mask)\n",
        "\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    pred, true = predictions_labels(predictions, label_ids)\n",
        "\n",
        "    all_pred_labels.extend(pred)\n",
        "    all_true_labels.extend(true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ESaLntjdAfYF",
        "outputId": "89e992ae-45a6-41d8-a5c2-a7817d1f8af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8887    0.9263    0.9071      2932\n",
            "           1     0.5773    0.4646    0.5148       635\n",
            "\n",
            "    accuracy                         0.8441      3567\n",
            "   macro avg     0.7330    0.6954    0.7110      3567\n",
            "weighted avg     0.8333    0.8441    0.8373      3567\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The final score in the test set (classification report)\n",
        "\n",
        "# print(classification_report(all_pred_labels,all_true_labels, digits = 4))\n",
        "print(classification_report(all_true_labels,all_pred_labels, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2zqXgAK1zy6Y",
        "outputId": "cbffe5af-0895-4a6a-e514-66169d2793e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2745,  187],\n",
              "       [ 342,  293]], dtype=int64)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confusion matrix in thetest set\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjYA3xD-VEdC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e5d40f71764e9994ec9223756a8e69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b3d8d6fde64d82ad49dc81b193275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc8b1500a1c41bd807761a54bf916bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e5d40f71764e9994ec9223756a8e69",
            "placeholder": "​",
            "style": "IPY_MODEL_6d1c543f9c8e431582ea5bee80a1a1aa",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "6d1c543f9c8e431582ea5bee80a1a1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71cbdcbf71284cfd96b9ad5259f1c7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b478ab8c8e4a0daa999aad57e95ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bc8b1500a1c41bd807761a54bf916bb",
              "IPY_MODEL_9ef62896ca1b43c18c1adf8a282ef398",
              "IPY_MODEL_cc4bb9d6a8e948cba93d31d073ac03af"
            ],
            "layout": "IPY_MODEL_a864f46b0bd545a7bd1e974c107e4ef8"
          }
        },
        "9ef62896ca1b43c18c1adf8a282ef398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94092c637004e37a98cbbc13bc8a8b9",
            "max": 439621341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9a4f2122c874921a99f81f72b49c8c1",
            "value": 439621341
          }
        },
        "a864f46b0bd545a7bd1e974c107e4ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a4f2122c874921a99f81f72b49c8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc4bb9d6a8e948cba93d31d073ac03af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71cbdcbf71284cfd96b9ad5259f1c7c0",
            "placeholder": "​",
            "style": "IPY_MODEL_26b3d8d6fde64d82ad49dc81b193275f",
            "value": " 440M/440M [00:04&lt;00:00, 29.7MB/s]"
          }
        },
        "e94092c637004e37a98cbbc13bc8a8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}