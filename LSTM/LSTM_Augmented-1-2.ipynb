{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTqhrPaSeE-z"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL1iFjECh3_6",
        "outputId": "5d79f4fe-b9b4-4c77-cd70-016febbf69f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers -qq\n",
        "# !pip install sentencepiece -qq\n",
        "# !pip install tokenizer -qq\n",
        "#!pip install nlpaug"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Cuda"
      ],
      "metadata": {
        "id": "ozXgZ7fGO4g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvNcjrGHO3ZY",
        "outputId": "1e0d4e6c-ed12-4994-97ba-d506f3f97a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-pzooQXh5S7"
      },
      "source": [
        "##Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlcEsxrXOWBm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def to_df(x, y):\n",
        "    d = {\"text\": x, \"label\": y}\n",
        "    return pd.DataFrame(d)\n",
        "\n",
        "def split_3(df, test_size=0.2, valid_size=0.2):\n",
        "    _df = df.copy().sample(frac=1).reset_index()\n",
        "    _df = _df[[\"text\", \"label\"]]\n",
        "\n",
        "    x = df[\"text\"].copy()\n",
        "    y = df[\"label\"].copy()\n",
        "    #split train-test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y, random_state=SEED)\n",
        "    # split train-valid\n",
        "    x, y = x_train, y_train\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=valid_size, stratify=y, random_state=SEED)\n",
        "    return to_df(x_train, y_train), to_df(x_valid, y_valid), to_df(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTMXPNE2W6NJ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from itertools import chain\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "from nlpaug.util import Action\n",
        "\n",
        "\n",
        "alpha_common_error = 0.10\n",
        "alpha_common_error_char = 0.05\n",
        "aug1_OCR = nac.OcrAug(aug_word_p=alpha_common_error)\n",
        "aug2_Rins = nac.RandomCharAug(action=\"insert\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug3_Rsub = nac.RandomCharAug(action=\"substitute\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug4_Rswa = nac.RandomCharAug(action=\"swap\", aug_word_p=alpha_common_error,aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char) #\n",
        "aug5_Rdel = nac.RandomCharAug(action=\"delete\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug6_Kb = nac.KeyboardAug(aug_word_p=alpha_common_error)\n",
        "aug7_Split = naw.SplitAug(aug_p=alpha_common_error)\n",
        "\n",
        "\n",
        "def text2augment(text, m):\n",
        "    output = [text, ]\n",
        "\n",
        "    temp = random.sample(range(0, 7), m - 1)\n",
        "\n",
        "    if 0 in temp:\n",
        "        output.append( *aug1_OCR.augment(text))\n",
        "    if 1 in temp:\n",
        "        output.append( *aug2_Rins.augment(text))\n",
        "    if 2 in temp:\n",
        "        output.append( *aug3_Rsub.augment(text))\n",
        "    if 3 in temp:\n",
        "        output.append( *aug4_Rswa.augment(text))\n",
        "    if 4 in temp:\n",
        "        output.append( *aug5_Rdel.augment(text))\n",
        "    if 5 in temp:\n",
        "        output.append( *aug6_Kb.augment(text))\n",
        "    if 6 in temp:\n",
        "        output.append( *aug7_Split.augment(text))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def aug_replicate(y_labels):\n",
        "    return list(chain(* [[y]*(1 if y == 0 else 2) for y in y_labels] ))\n",
        "\n",
        "def aug_text(x_text, y_labels):\n",
        "    x_text = [ text2augment(x, 1 if y == 0 else 2) for x, y in zip(x_text, y_labels)]\n",
        "    return pd.Series(list(chain(*x_text)), index=None)\n",
        "\n",
        "def split_3_aug(df, test_size=0.2, valid_size=0.2):\n",
        "    _df = df.copy().sample(frac=1).reset_index()\n",
        "    _df = _df[[\"text\", \"label\"]]\n",
        "\n",
        "    x = _df[\"text\"].copy()\n",
        "    y = _df[\"label\"].copy()\n",
        "    #split train-test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y, random_state=SEED)\n",
        "    # augment\n",
        "    # x_test = aug_text(x_test, y_test)\n",
        "    # y_test = aug_replicate(y_test)\n",
        "    # split train-valid\n",
        "    x, y = x_train, y_train\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=valid_size, stratify=y, random_state=SEED)\n",
        "    # augment\n",
        "    x_train = aug_text(x_train, y_train)\n",
        "    y_train = aug_replicate(y_train)\n",
        "    x_valid = aug_text(x_valid, y_valid)\n",
        "    y_valid = aug_replicate(y_valid)\n",
        "\n",
        "    print(x_valid.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_valid))\n",
        "\n",
        "    print(x_train.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_train))\n",
        "\n",
        "    return to_df(x_train, y_train), to_df(x_valid, y_valid), to_df(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01wjOuCvOWBn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tname_data = \"./hsd_merge_cleaned_lowered\"\n",
        "data = pd.read_csv(f\"{tname_data}.csv\")\n",
        "\n",
        "train, valid, test = split_3_aug(data)\n",
        "\n",
        "X_train = train['text']\n",
        "y_train = train['label']\n",
        "\n",
        "X_valid = valid['text']\n",
        "y_valid = valid['label']\n",
        "\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHV2PrVfiBLg"
      },
      "source": [
        "# Extract feature by using BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MreD1ev6AgXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "train_sentences = list(train['text'].values)\n",
        "train_labels = list(train['label'].values)\n",
        "\n",
        "valid_sentences = list(valid['text'].values)\n",
        "valid_labels = list(valid['label'].values)\n",
        "\n",
        "test_sentences = list(test['text'].values)\n",
        "test_labels = list(test['label'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNVMN4YPiNjp"
      },
      "source": [
        "Load tokenizer of BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8SPqPcA8BS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PNp5aRVA-Hb",
        "outputId": "60aa7493-44a4-47e9-9917-bca115729f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(17, 404),\n",
              " (15, 380),\n",
              " (23, 354),\n",
              " (18, 344),\n",
              " (24, 343),\n",
              " (19, 340),\n",
              " (22, 337),\n",
              " (21, 336),\n",
              " (20, 335),\n",
              " (14, 328),\n",
              " (12, 325),\n",
              " (13, 325),\n",
              " (16, 325),\n",
              " (26, 310),\n",
              " (9, 302),\n",
              " (11, 298),\n",
              " (10, 293),\n",
              " (25, 277),\n",
              " (29, 271),\n",
              " (27, 270),\n",
              " (28, 262),\n",
              " (31, 210),\n",
              " (7, 210),\n",
              " (32, 201),\n",
              " (30, 200),\n",
              " (8, 192),\n",
              " (33, 189),\n",
              " (34, 148),\n",
              " (6, 144),\n",
              " (36, 137),\n",
              " (38, 121),\n",
              " (53, 117),\n",
              " (39, 117),\n",
              " (35, 117),\n",
              " (37, 117),\n",
              " (40, 116),\n",
              " (5, 115),\n",
              " (42, 112),\n",
              " (50, 111),\n",
              " (43, 109),\n",
              " (54, 109),\n",
              " (41, 106),\n",
              " (44, 106),\n",
              " (49, 105),\n",
              " (45, 102),\n",
              " (48, 101),\n",
              " (52, 100),\n",
              " (56, 98),\n",
              " (51, 98),\n",
              " (46, 97),\n",
              " (47, 92),\n",
              " (55, 85),\n",
              " (58, 85),\n",
              " (57, 84),\n",
              " (4, 67),\n",
              " (59, 61),\n",
              " (60, 58),\n",
              " (61, 55),\n",
              " (64, 38),\n",
              " (62, 36),\n",
              " (65, 33),\n",
              " (3, 31),\n",
              " (66, 28),\n",
              " (63, 26),\n",
              " (67, 17),\n",
              " (69, 13),\n",
              " (68, 12),\n",
              " (2, 7),\n",
              " (72, 6),\n",
              " (70, 6),\n",
              " (1, 4),\n",
              " (71, 2),\n",
              " (73, 1),\n",
              " (74, 1),\n",
              " (81, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "#choose max_length for phobert model based on the input length\n",
        "\n",
        "max_length = 0\n",
        "list_len=[]\n",
        "for sentence in train_sentences:\n",
        "    length = len(tokenizer.tokenize(sentence))\n",
        "    list_len.append(length)\n",
        "\n",
        "from collections import Counter\n",
        "Counter(list_len).most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5lBYCTD9bU"
      },
      "outputs": [],
      "source": [
        "# Encode train label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "encoded_labels = le.transform(train_labels)\n",
        "encoded_test_labels = le.transform(valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9XdWNkpFBgH",
        "outputId": "37e544f2-c9b6-468d-9d53-e91dd030ea80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  maripan ctm siempre mandandose cagas\n",
            "Token IDs: tensor([    4,  4352,  5249,  1016, 30940, 30943,  2032,  4521, 30935,  2610,\n",
            "         1285,  1723,     5,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Tokens IDs tensor\n",
        "\n",
        "def encoder_generator(sentences,labels):\n",
        "\n",
        "    sent_index = []\n",
        "    input_ids = []\n",
        "    attention_masks =[]\n",
        "\n",
        "    for index,sent in enumerate(sentences):\n",
        "\n",
        "        sent_index.append(index)\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=50,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             truncation = True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids,dim=0).cuda()\n",
        "    attention_masks = torch.cat(attention_masks,dim=0).cuda()\n",
        "    labels = torch.tensor(labels).cuda()\n",
        "    sent_index = torch.tensor(sent_index).cuda()\n",
        "\n",
        "    return sent_index,input_ids,attention_masks,labels\n",
        "\n",
        "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,encoded_labels)\n",
        "valid_sent_index,valid_input_ids,valid_attention_masks,valid_encoded_label_tensors = encoder_generator(valid_sentences,encoded_test_labels)\n",
        "print('Original: ', train_sentences[0])\n",
        "print('Token IDs:', train_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYbqZ7NMMWw",
        "outputId": "a84b07ad-cf46-4cbf-f00a-87f6b9ae1c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data samples is 11413\n",
            "valid data samples is 2854\n"
          ]
        }
      ],
      "source": [
        "# Connvert train, dev input by using TensorDataset\n",
        "\n",
        "from torch.utils.data import TensorDataset,random_split\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
        "valid_dataset = TensorDataset(valid_input_ids,valid_attention_masks,valid_encoded_label_tensors)\n",
        "\n",
        "print('train data samples is {}'.format(len(train_dataset)))\n",
        "print(\"valid data samples is {}\".format(len(valid_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em9Q1v0BMZZX"
      },
      "outputs": [],
      "source": [
        "# Set cuda by using device\n",
        "\n",
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "bs=128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=bs)\n",
        "valid_data_loader = DataLoader(valid_dataset,\n",
        "                              sampler=RandomSampler(valid_dataset),\n",
        "                              batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEtD7kn4jbTl"
      },
      "source": [
        "Load model BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQiHRn2zMdIJ",
        "outputId": "f729fced-b150-4bf2-bfd6-92cc838ba237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "beto = AutoModel.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "beto = beto.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEv63LPpjkcK"
      },
      "source": [
        "# Build LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q44-J-QWMgKQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            # bidirectional = True,\n",
        "                            dropout = 0.1,\n",
        "                            batch_first = True\n",
        "                           )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2,output_dim)\n",
        "\n",
        "    def forward(self, x, x_lengths):\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, torch.sum(x_lengths, dim=1).cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        packed_output,(hidden_state,cell_state) = self.lstm(packed_embedded)\n",
        "\n",
        "        hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "\n",
        "        logits=self.fc(hidden)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDBluC0FOWBo"
      },
      "outputs": [],
      "source": [
        "# Definir los parámetros del modelo\n",
        "vocab_size = 31002#tamaño del vocabulario\n",
        "embedding_dim = 768 #Dimension de los vectores de embedding\n",
        "hidden_size = 128  # Tamaño de la capa oculta del LSTM\n",
        "num_layers = 2  # Número de capas del LSTM\n",
        "output_size = 2  # Tamaño de la salida\n",
        "\n",
        "# Crear una instancia del modelo LSTM\n",
        "LSTMmodel = LSTMModel(vocab_size, embedding_dim, hidden_size, output_size, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8QAddNK0rMj",
        "outputId": "a675e83c-9598-4ec0-af3a-4777f57ee836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (embedding): Embedding(31002, 768)\n",
            "  (lstm): LSTM(768, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imprimir el modelo\n",
        "print(LSTMmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITmi7WZDMsl6"
      },
      "outputs": [],
      "source": [
        "# Optimizer and criterion\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "model_parameters = list(LSTMmodel.parameters())\n",
        "\n",
        "optimizer = optim.Adam(model_parameters,lr=2e-5,eps=1e-8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyp8HhAxMvQH"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy per batch during train\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrVcBEVoMxov"
      },
      "outputs": [],
      "source": [
        "# Def for training\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_data_loader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        loss = criterion(predictions, b_labels)\n",
        "\n",
        "        acc = categorical_accuracy(predictions, b_labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQGFfnFMz-d"
      },
      "outputs": [],
      "source": [
        "# Class for predict label\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    pred = np.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_4Y1RhlM17e"
      },
      "outputs": [],
      "source": [
        "# Evaluate loss, acc  and f1-macro\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
        "def eval(model):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    total_predictions = []\n",
        "    total_true = []\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in tqdm(valid_data_loader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "            loss = criterion(predictions, b_labels)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            pred,true = predictions_labels(predictions,label_ids)\n",
        "\n",
        "            all_pred_labels.extend(pred)\n",
        "            all_true_labels.extend(true)\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
        "\n",
        "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICyenO-tM35S"
      },
      "outputs": [],
      "source": [
        "# Time for training\n",
        "\n",
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OrAOzamNC0e",
        "outputId": "0841707e-b6f5-42fd-b58c-ac6a27c737ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (lstm): LSTM(768, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "# Set device and gpu\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "LSTMmodel.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJBkClEkam2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vlSQghHOWBp"
      },
      "outputs": [],
      "source": [
        "tempname = './lstm_aug_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfHllZjgM5uw",
        "outputId": "b08606ba-0ad9-4514-a8ce-d0311bec16d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 34.30it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 124.41it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.575 | Train acc: 81.09%\n",
            "\t Val. Loss: 0.490 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.490 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 33.87it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 169.55it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.471 | Train acc: 82.29%\n",
            "\t Val. Loss: 0.470 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.470 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 40.25it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 166.89it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.462 | Train acc: 82.20%\n",
            "\t Val. Loss: 0.459 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.459 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.89it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 167.95it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.456 | Train acc: 82.33%\n",
            "\t Val. Loss: 0.465 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.465 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.96it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 163.36it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.453 | Train acc: 82.16%\n",
            "\t Val. Loss: 0.450 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.450 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 38.21it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 124.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2854\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.41      0.45      2854\n",
            "weighted avg       1.00      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.444 | Train acc: 82.20%\n",
            "\t Val. Loss: 0.450 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.450 |  Val. F1: 45.12%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 33.54it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 169.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90      2844\n",
            "           1       0.01      0.50      0.02        10\n",
            "\n",
            "    accuracy                           0.82      2854\n",
            "   macro avg       0.50      0.66      0.46      2854\n",
            "weighted avg       0.99      0.82      0.90      2854\n",
            "\n",
            "accuracy = 0.82\n",
            "model saved\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.429 | Train acc: 82.38%\n",
            "\t Val. Loss: 0.433 |  Val. acc: 82.20%\n",
            "\t Val. Loss: 0.433 |  Val. F1: 46.07%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.86it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 166.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.83      0.90      2810\n",
            "           1       0.05      0.61      0.10        44\n",
            "\n",
            "    accuracy                           0.83      2854\n",
            "   macro avg       0.52      0.72      0.50      2854\n",
            "weighted avg       0.98      0.83      0.89      2854\n",
            "\n",
            "accuracy = 0.83\n",
            "model saved\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.415 | Train acc: 82.32%\n",
            "\t Val. Loss: 0.422 |  Val. acc: 82.55%\n",
            "\t Val. Loss: 0.422 |  Val. F1: 50.06%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 40.27it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 164.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.84      0.91      2774\n",
            "           1       0.10      0.64      0.17        80\n",
            "\n",
            "    accuracy                           0.83      2854\n",
            "   macro avg       0.54      0.74      0.54      2854\n",
            "weighted avg       0.96      0.83      0.88      2854\n",
            "\n",
            "accuracy = 0.83\n",
            "model saved\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.385 | Train acc: 83.04%\n",
            "\t Val. Loss: 0.410 |  Val. acc: 82.97%\n",
            "\t Val. Loss: 0.410 |  Val. F1: 53.93%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 40.07it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 171.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91      2699\n",
            "           1       0.20      0.65      0.30       155\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.59      0.75      0.60      2854\n",
            "weighted avg       0.93      0.84      0.88      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.360 | Train acc: 83.92%\n",
            "\t Val. Loss: 0.392 |  Val. acc: 83.78%\n",
            "\t Val. Loss: 0.392 |  Val. F1: 60.49%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 38.07it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 127.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91      2649\n",
            "           1       0.25      0.61      0.35       205\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.61      0.73      0.63      2854\n",
            "weighted avg       0.91      0.84      0.87      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 11 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.336 | Train acc: 85.15%\n",
            "\t Val. Loss: 0.386 |  Val. acc: 83.78%\n",
            "\t Val. Loss: 0.386 |  Val. F1: 62.90%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 33.31it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 163.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.86      0.91      2628\n",
            "           1       0.27      0.61      0.38       226\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.62      0.73      0.64      2854\n",
            "weighted avg       0.91      0.84      0.87      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 12 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.317 | Train acc: 85.85%\n",
            "\t Val. Loss: 0.387 |  Val. acc: 83.95%\n",
            "\t Val. Loss: 0.387 |  Val. F1: 64.20%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.58it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 170.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91      2567\n",
            "           1       0.33      0.59      0.43       287\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.64      0.73      0.67      2854\n",
            "weighted avg       0.89      0.84      0.86      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 13 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.296 | Train acc: 87.03%\n",
            "\t Val. Loss: 0.382 |  Val. acc: 83.99%\n",
            "\t Val. Loss: 0.382 |  Val. F1: 66.61%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.92it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 165.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91      2553\n",
            "           1       0.35      0.59      0.44       301\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.65      0.73      0.67      2854\n",
            "weighted avg       0.88      0.84      0.86      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 14 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.278 | Train acc: 88.20%\n",
            "\t Val. Loss: 0.382 |  Val. acc: 84.13%\n",
            "\t Val. Loss: 0.382 |  Val. F1: 67.38%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 38.63it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 164.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91      2561\n",
            "           1       0.35      0.61      0.45       293\n",
            "\n",
            "    accuracy                           0.85      2854\n",
            "   macro avg       0.65      0.74      0.68      2854\n",
            "weighted avg       0.89      0.85      0.86      2854\n",
            "\n",
            "accuracy = 0.85\n",
            "model saved\n",
            "Epoch: 15 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.258 | Train acc: 89.11%\n",
            "\t Val. Loss: 0.387 |  Val. acc: 84.55%\n",
            "\t Val. Loss: 0.387 |  Val. F1: 67.98%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 37.94it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 126.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90      2433\n",
            "           1       0.44      0.54      0.49       421\n",
            "\n",
            "    accuracy                           0.83      2854\n",
            "   macro avg       0.68      0.71      0.69      2854\n",
            "weighted avg       0.85      0.83      0.84      2854\n",
            "\n",
            "accuracy = 0.83\n",
            "model saved\n",
            "Epoch: 16 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.241 | Train acc: 89.84%\n",
            "\t Val. Loss: 0.383 |  Val. acc: 83.29%\n",
            "\t Val. Loss: 0.383 |  Val. F1: 69.34%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 35.16it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 168.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.91      2489\n",
            "           1       0.41      0.58      0.48       365\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.67      0.73      0.69      2854\n",
            "weighted avg       0.87      0.84      0.85      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 17 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.221 | Train acc: 90.91%\n",
            "\t Val. Loss: 0.393 |  Val. acc: 84.13%\n",
            "\t Val. Loss: 0.393 |  Val. F1: 69.37%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 40.06it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 167.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.88      0.91      2509\n",
            "           1       0.41      0.60      0.48       345\n",
            "\n",
            "    accuracy                           0.85      2854\n",
            "   macro avg       0.67      0.74      0.70      2854\n",
            "weighted avg       0.88      0.85      0.86      2854\n",
            "\n",
            "accuracy = 0.85\n",
            "model saved\n",
            "Epoch: 18 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.207 | Train acc: 91.53%\n",
            "\t Val. Loss: 0.402 |  Val. acc: 84.55%\n",
            "\t Val. Loss: 0.402 |  Val. F1: 69.61%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.86it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 159.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.91      2474\n",
            "           1       0.44      0.58      0.50       380\n",
            "\n",
            "    accuracy                           0.84      2854\n",
            "   macro avg       0.68      0.73      0.70      2854\n",
            "weighted avg       0.87      0.84      0.85      2854\n",
            "\n",
            "accuracy = 0.84\n",
            "model saved\n",
            "Epoch: 19 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.187 | Train acc: 92.40%\n",
            "\t Val. Loss: 0.413 |  Val. acc: 84.37%\n",
            "\t Val. Loss: 0.413 |  Val. F1: 70.26%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:02<00:00, 39.91it/s]\n",
            "100%|██████████| 23/23 [00:00<00:00, 166.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.88      0.91      2512\n",
            "           1       0.41      0.61      0.49       342\n",
            "\n",
            "    accuracy                           0.85      2854\n",
            "   macro avg       0.67      0.74      0.70      2854\n",
            "weighted avg       0.88      0.85      0.86      2854\n",
            "\n",
            "accuracy = 0.85\n",
            "model saved\n",
            "Epoch: 20 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.172 | Train acc: 93.35%\n",
            "\t Val. Loss: 0.443 |  Val. acc: 84.72%\n",
            "\t Val. Loss: 0.443 |  Val. F1: 69.87%\n",
            "=============Epoch Ended==============\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "\n",
        "best_macro_f1 = float('0')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train(LSTMmodel)\n",
        "    valid_loss,valid_acc,macro_f1 = eval(LSTMmodel)\n",
        "    end_time = time.time()\n",
        "\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if macro_f1 > best_macro_f1:\n",
        "        best_macro_f1 = macro_f1\n",
        "    torch.save(LSTMmodel, tempname+'_task2a_2.pt')\n",
        "    print(\"model saved\")\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc: {valid_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1: {macro_f1*100:.2f}%')\n",
        "    print('=============Epoch Ended==============')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyQlcVfnCWHw"
      },
      "outputs": [],
      "source": [
        "# Save BETO and CNN\n",
        "\n",
        "torch.save(LSTMmodel,tempname + 'module2_part1.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCzo5AKq8lka"
      },
      "source": [
        "## EVALUATING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftons15Hw8lB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af19d833-8e3f-41a9-ef31-ccef72660e70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (lstm): LSTM(768, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Load phobert and cnn\n",
        "\n",
        "import torch\n",
        "LSTMmodel = torch.load(tempname + '_task2a_2.pt')\n",
        "LSTMmodel.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6sFPdMFlPRp"
      },
      "source": [
        "Predict label from true label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Co-AvE_Ehq",
        "outputId": "55c897ee-cbf5-44bd-e56b-07ad51e5fc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 28/28 [00:00<00:00, 122.96it/s]\n"
          ]
        }
      ],
      "source": [
        "test_sent_index, test_input_ids, test_attention_masks, test_encoded_label_tensors = encoder_generator(test_sentences,test_labels)\n",
        "test_dataset = TensorDataset(test_input_ids,test_attention_masks,test_encoded_label_tensors)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset,\n",
        "                              sampler=RandomSampler(test_dataset),\n",
        "                              batch_size=bs)\n",
        "\n",
        "all_pred_labels = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(test_data_loader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    predictions = LSTMmodel(b_input_ids,b_input_mask)\n",
        "\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    pred, true = predictions_labels(predictions, label_ids)\n",
        "\n",
        "    all_pred_labels.extend(pred)\n",
        "    all_true_labels.extend(true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESaLntjdAfYF",
        "outputId": "61e368c6-9806-4978-e524-5386418b80d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8874    0.9035    0.8954      2932\n",
            "           1     0.5137    0.4709    0.4914       635\n",
            "\n",
            "    accuracy                         0.8265      3567\n",
            "   macro avg     0.7006    0.6872    0.6934      3567\n",
            "weighted avg     0.8209    0.8265    0.8235      3567\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The final score in the test set (classification report)\n",
        "\n",
        "# print(classification_report(all_pred_labels,all_true_labels, digits = 4))\n",
        "print(classification_report(all_true_labels,all_pred_labels, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zqXgAK1zy6Y",
        "outputId": "e90ce0f7-e1e8-460c-c06c-672e749f5dd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2649,  283],\n",
              "       [ 336,  299]])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "# Confusion matrix in thetest set\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaiHzEqGOWBq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}